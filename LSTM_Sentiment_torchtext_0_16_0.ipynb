{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChanglinWu/DL/blob/main/LSTM_Sentiment_torchtext_0_16_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-raj47LUep9"
      },
      "source": [
        "# LSTM Sentiment Analysis\n",
        "\n",
        "In this example notebook, we will demonstrate how to build and train a Long Short-Term Memory (LSTM) network using the IMDB dataset. LSTM is a type of recurrent neural network (RNN) that is particularly effective in capturing sequential information and long-term dependencies in text data. By utilizing LSTM, we can create a powerful model capable of understanding the sentiment expressed in movie reviews.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/rishikksh20/IMDB-Movie-Review-sentiment-Analysis/558b1a1eef30b5806f27891019c9dcad6d53cd88/Images/SentimentAnalysis16.png'>\n",
        "\n",
        "The IMDB (Internet Movie Database) dataset is a commonly used benchmark dataset for sentiment analysis tasks in natural language processing. It consists of a large collection of movie reviews, with each review labeled as either positive or negative based on the sentiment expressed in the text. The dataset is split into a training set and a test set, with 25,000 reviews in each set.\n",
        "\n",
        "References:\n",
        "\n",
        "- GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss21\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ju7W4JefVdpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda222dc-7892-494d-df8c-5ada70790118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-27 12:33:25.262902: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-27 12:33:25.262962: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-27 12:33:25.263005: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-27 12:33:25.274746: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-27 12:33:27.103165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-10-27 12:33:28.383329: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-27 12:33:28.383854: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-27 12:33:28.384059: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "# Downgrade the torchtext version to 0.16.0\n",
        "!pip install torchtext==0.16.0 -qqq\n",
        "!python -m spacy download en_core_web_sm -qqq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSYlZh7FPKPR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "import time\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qopUXRqkRbl6"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 123\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "VOCABULARY_SIZE = 20000\n",
        "LEARNING_RATE = 0.005\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 15\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "NUM_CLASSES = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdDr12oKPRyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce39cc87-06fc-4cae-ea76-590495760d70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "is_cuda = torch.cuda.is_available()\n",
        "if is_cuda:\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRzkC95ZUrCk"
      },
      "source": [
        "# Download Dataset\n",
        "The following cells will download the IMDB movie review dataset (http://ai.stanford.edu/~amaas/data/sentiment/) for positive-negative sentiment classification in as CSV-formatted file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGdTFT9VPULr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44582efb-2102-41f4-b151-43cca934cb26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-27 12:33:40--  https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch08/movie_data.csv.gz [following]\n",
            "--2023-10-27 12:33:40--  https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch08/movie_data.csv.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26521894 (25M) [application/octet-stream]\n",
            "Saving to: ‘movie_data.csv.gz’\n",
            "\n",
            "movie_data.csv.gz   100%[===================>]  25.29M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-10-27 12:33:41 (256 MB/s) - ‘movie_data.csv.gz’ saved [26521894/26521894]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz\n",
        "\n",
        "!gunzip -f movie_data.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "zhtrfWbHUxTU",
        "outputId": "21bae660-0d16-4366-c913-d9567f0dc4eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
              "1  OK... so... I really like Kris Kristofferson a...          0\n",
              "2  ***SPOILER*** Do not read this, if you think a...          0\n",
              "3  hi for all the people who have seen this wonde...          1\n",
              "4  I recently bought the DVD, forgetting just how...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-604a28ca-b9ff-497a-851e-2d0d9fa446f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi for all the people who have seen this wonde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I recently bought the DVD, forgetting just how...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-604a28ca-b9ff-497a-851e-2d0d9fa446f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-604a28ca-b9ff-497a-851e-2d0d9fa446f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-604a28ca-b9ff-497a-851e-2d0d9fa446f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-62e71b8f-0663-43cb-bbf6-86e9f8f771cc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62e71b8f-0663-43cb-bbf6-86e9f8f771cc')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-62e71b8f-0663-43cb-bbf6-86e9f8f771cc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df = pd.read_csv('movie_data.csv')\n",
        "print(len(df))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRgvwDqdU1y3"
      },
      "outputs": [],
      "source": [
        "del df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KseI_ihuU_nQ"
      },
      "source": [
        "# Prepare Dataset with Torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4z_WkVFFVH8D",
        "outputId": "76935202-44a6-4fa9-8b98-63b338804c90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/utils/common.py:149: UserWarning: Lambda function is not supported by pickle, please use regular python function or functools.partial instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# ### Defining the feature processing\n",
        "import torchdata.datapipes as dp\n",
        "datapipe = dp.iter.FileLister(['.']).filter(filter_fn=lambda filename: filename.endswith('.csv')) # Read the csv file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(datapipe))\n",
        "datapipe = dp.iter.FileOpener(datapipe, mode='rt')\n",
        "datapipe = datapipe.parse_csv(delimiter=',', skip_lines=1) # skip_lines = 0 contains the header the csv file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT2ehVIIi8CW",
        "outputId": "2cac121c-2314-49ed-ab09-adbb81f9fd51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['./movie_data.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Dataset into Train/Validation/Test\n",
        "Split the dataset into training, validation, and test partitions:"
      ],
      "metadata": {
        "id": "KR8NUOXAlXoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the attributes of the datapipe\n",
        "N_ROWS = 50000\n",
        "train, valid, test = datapipe.random_split(total_length=N_ROWS, weights={\"train\": 0.8 * 0.85, \"valid\": 0.8 * 0.15, \"test\": 0.2}, seed= RANDOM_SEED)"
      ],
      "metadata": {
        "id": "zD0AANKJ1e1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Num Train: {len(train)}, Num Validation: {len(valid)}, Num Test: {len(test)}')\n",
        "temp_list = list(train)\n",
        "print(temp_list[0], len(temp_list[0])) # each_iter, length of each_iter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uugvE6Z6WnV",
        "outputId": "75c3661b-c320-4ec5-b483-dc75e2f48eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Train: 34000, Num Validation: 6000, Num Test: 10000\n",
            "['In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"Murder in Greenwich\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available', '1'] 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Vocabulary\n",
        "Build the vocabulary based on the top \"VOCABULARY_SIZE\" words:"
      ],
      "metadata": {
        "id": "IuEmbqFG06SC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "eng = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def engTokenize(text):\n",
        "  \"\"\"\n",
        "  Tokenize an English text and return a list of tokens\n",
        "  \"\"\"\n",
        "  return [token.text for token in eng.tokenizer(text)]"
      ],
      "metadata": {
        "id": "EYCvJosNoQir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getToken(data_iter):\n",
        "  # Return the token for the data_iter\n",
        "  for text, label in data_iter:\n",
        "    yield engTokenize(text)\n",
        "\n",
        "def getLabel(data_iter):\n",
        "  # Return the label for the data_iter\n",
        "  for text, label in data_iter:\n",
        "    yield label"
      ],
      "metadata": {
        "id": "qocFeUaw1MJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter, OrderedDict\n",
        "\n",
        "def count_freq(iterator):\n",
        "  counter = Counter()\n",
        "  for tokens in iterator:\n",
        "    counter.update(tokens)\n",
        "  return counter"
      ],
      "metadata": {
        "id": "xIY6fwPv-6NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to build the vocabulary\n",
        "train_tokens = getToken(train)\n",
        "train_labels = getLabel(train)"
      ],
      "metadata": {
        "id": "Sc2YxFuyV1il"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "train_vocab = build_vocab_from_iterator(train_tokens, specials= ['<pad>', '<unk>'], special_first=True, max_tokens= VOCABULARY_SIZE + 2)\n",
        "\n",
        "train_vocab.set_default_index(train_vocab['<unk>'])"
      ],
      "metadata": {
        "id": "0mQSi9kPY0IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Vocabulary size: {len(train_vocab)}')\n",
        "\n",
        "print(train_vocab.get_stoi()['the'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uv-8Nxec2Lj",
        "outputId": "d3c7a675-83eb-440b-f8f3-c52fb8154d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 20002\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Look at most common words:"
      ],
      "metadata": {
        "id": "-EuDHhLbpS4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_vocab.get_itos()[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iq5qKW4npZI6",
        "outputId": "4b1d81c0-c378-4951-b681-4de85cd95774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<pad>', '<unk>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting a string to an integer:\n",
        "\n"
      ],
      "metadata": {
        "id": "yyaRPC4fpeww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_vocab.get_stoi()['the'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJm9Mqbwpg32",
        "outputId": "d22fc0fb-608f-4677-ffcc-c2e5efc3a11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class labels:"
      ],
      "metadata": {
        "id": "2SzuBfKQpnpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(count_freq(train_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49RY6cLjpomK",
        "outputId": "38023537-c77b-4b97-821c-b36ad117c377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'0': 17103, '1': 16897})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numericalize sentences using vocabulary"
      ],
      "metadata": {
        "id": "2HJfmb1nrtvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext.transforms as T\n",
        "\n",
        "def getTransform(vocab):\n",
        "    \"\"\"\n",
        "    Create transforms based on given vocabulary. The returned transform is applied to sequence\n",
        "    of tokens.\n",
        "    \"\"\"\n",
        "    text_tranform = T.Sequential(\n",
        "        ## converts the sentences to indices based on given vocabulary\n",
        "        T.VocabTransform(vocab=vocab),\n",
        "    )\n",
        "    return text_tranform\n",
        "\n",
        "def applyTransform(sequence_pair):\n",
        "    \"\"\"\n",
        "    Apply transforms to sequence of tokens in a sequence pair\n",
        "    \"\"\"\n",
        "\n",
        "    return (\n",
        "        getTransform(train_vocab)(engTokenize(sequence_pair[0])), [int(sequence_pair[1])]\n",
        "    )\n"
      ],
      "metadata": {
        "id": "yEmbB60YrrNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.map(applyTransform)\n",
        "valid = valid.map(applyTransform)\n",
        "test = test.map(applyTransform)\n",
        "\n",
        "# Check the state\n",
        "temp_list = list(train)\n",
        "print(temp_list[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jai04XYlsD1h",
        "outputId": "55aeda5f-e031-4e40-c1e1-c4b9f22ac38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([158, 6528, 3, 2, 2236, 4408, 1, 28, 4723, 3209, 30, 1149, 8, 2, 355, 17, 759, 1603, 7, 9241, 1, 3, 18236, 3, 8683, 4, 744, 2, 1, 1266, 3, 11865, 7, 2382, 3, 80, 19, 1978, 10, 2, 11001, 7, 54, 440, 6, 54, 675, 4932, 1, 4, 11594, 17, 127, 179, 353, 3, 2, 636, 1643, 1, 28, 1527, 1, 30, 3, 44, 9, 5, 1183, 3818, 1624, 13, 52, 3305, 10, 6878, 23, 1, 10, 1, 5956, 3477, 6, 1681, 8, 1, 3, 1128, 8, 4111, 2, 468, 20, 35, 1942, 1912, 1, 28, 3786, 4046, 30, 20, 2, 1305, 7, 524, 5, 299, 4, 25, 6453, 14111, 6, 57, 33, 3152, 109, 3, 26, 20, 2, 1503, 7, 2, 5695, 1624, 1260, 9486, 28, 666, 12929, 30, 13, 19, 10, 2883, 7, 2, 3917, 10, 2, 1393, 15, 3, 47, 1885, 2, 1922, 6, 5, 6901, 7, 756, 6, 328, 8, 1046, 2, 15928, 18, 1, 10, 18236, 14, 9, 5, 60, 261, 22, 3, 20, 2, 336, 77, 7, 5, 675, 7, 5, 3495, 179, 181, 283, 13, 19, 2530, 41, 5, 2984, 2236, 660, 471, 19, 5, 3221, 4, 25, 989, 6, 1100, 267, 350, 76, 2494, 8, 1046, 2, 675, 23, 61, 88, 1902, 179, 4, 380, 3, 5, 1, 1624, 6, 7095, 1, 10, 6878, 19, 496, 8, 1, 112, 2, 4867, 912, 19, 2530, 4, 25, 1017, 298, 2, 3917, 7, 1643, 6, 2, 272, 557, 7, 4408, 10, 4594, 3, 26, 66, 9, 5, 616, 7, 2, 1484, 10, 2, 13346, 4, 399, 2242, 9, 17463, 18, 5946, 28, 3787, 2505, 366, 1], [1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Data Loaders (with bucket batch)"
      ],
      "metadata": {
        "id": "1C607pve0fXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sortBucket(bucket):\n",
        "    \"\"\"\n",
        "    Function to sort a given bucket. Here, we want to sort based on the length of\n",
        "    source and target sequence.\n",
        "    \"\"\"\n",
        "    return sorted(bucket, key=lambda x: (len(x[0])))"
      ],
      "metadata": {
        "id": "b_nv575j0ky6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.bucketbatch(\n",
        "    batch_size = BATCH_SIZE, batch_num=5,  bucket_num=1,\n",
        "    use_in_batch_shuffle=False, sort_key=sortBucket\n",
        ")\n",
        "valid = valid.bucketbatch(\n",
        "    batch_size = BATCH_SIZE, batch_num=5,  bucket_num=1,\n",
        "    use_in_batch_shuffle=False, sort_key=sortBucket\n",
        ")\n",
        "test = test.bucketbatch(\n",
        "    batch_size = BATCH_SIZE, batch_num=5,  bucket_num=1,\n",
        "    use_in_batch_shuffle=False, sort_key=sortBucket\n",
        ")"
      ],
      "metadata": {
        "id": "SyHTcvGT0-lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(list(train)[0])"
      ],
      "metadata": {
        "id": "KZPfC-8l1uQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def separateSourceTarget(sequence_pairs):\n",
        "    \"\"\"\n",
        "    input of form: `[(X_1,y_1), (X_2,y_2), (X_3,y_3), (X_4,y_4)]`\n",
        "    output of form: `((X_1,X_2,X_3,X_4), (y_1,y_2,y_3,y_4))`\n",
        "    \"\"\"\n",
        "    sources,targets = zip(*sequence_pairs)\n",
        "    return sources,targets\n",
        "\n",
        "## Apply the function to each element in the iterator\n",
        "train = train.map(separateSourceTarget)\n",
        "valid = valid.map(separateSourceTarget)\n",
        "test = test.map(separateSourceTarget)\n",
        "\n",
        "# print(list(train)[0])"
      ],
      "metadata": {
        "id": "OqRaOoz5CVN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_variable = list(train)[0]\n",
        "print(len(temp_variable))\n",
        "print(len(temp_variable[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0mRAouu3M1L",
        "outputId": "a3c4bf82-7cff-4ec7-9faf-5ea3b73b99bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(temp_variable[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B4By0d6X4xR",
        "outputId": "c71f5b36-5c78-4e76-a4c6-8f89755449e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0], [0], [0], [1], [1], [1], [0], [0], [1], [1], [1], [1], [0], [0], [1], [0], [0], [0], [1], [1], [1], [0], [0], [0], [1], [1], [0], [1], [1], [1], [1], [0], [0], [1], [0], [0], [0], [0], [1], [0], [0], [1], [0], [1], [0], [1], [0], [0], [0], [1], [0], [0], [1], [0], [1], [0], [0], [1], [0], [1], [0], [1], [0], [0], [0], [0], [1], [1], [0], [1], [1], [0], [0], [1], [1], [0], [0], [0], [0], [0], [0], [0], [1], [1], [1], [1], [0], [1], [0], [0], [0], [0], [1], [0], [1], [1], [1], [0], [1], [0], [0], [1], [1], [1], [1], [1], [1], [0], [0], [0], [0], [0], [0], [0], [1], [1], [0], [0], [0], [0], [0], [1], [1], [1], [1], [0], [1], [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding"
      ],
      "metadata": {
        "id": "4Zl572Fq3oOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def applyPadding(pair_of_sequences):\n",
        "    \"\"\"\n",
        "    Convert sequences to tensors and apply padding\n",
        "    \"\"\"\n",
        "    return (T.ToTensor(0)(list(pair_of_sequences[0])), torch.tensor(list(pair_of_sequences[1]), dtype= torch.long))\n",
        "\n",
        "train_pad = train.map(applyPadding)\n",
        "valid_pad = valid.map(applyPadding)\n",
        "test_pad = test.map(applyPadding)"
      ],
      "metadata": {
        "id": "LmQcV1Og3nsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the iterators (note that the number of rows depends on the longest document in the respective batch):"
      ],
      "metadata": {
        "id": "lwQxceZyrgy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train')\n",
        "# train_pad_value = next(iter(train_pad))\n",
        "for batch in train_pad:\n",
        "    print(f'Text matrix size: {batch[0].size()}')\n",
        "    print(f'Target vector size: {batch[1].size()}')\n",
        "    print(batch[0].dtype)\n",
        "    print(batch[1].dtype)\n",
        "    break\n",
        "\n",
        "print('\\nValid:')\n",
        "for batch in valid_pad:\n",
        "    print(f'Text matrix size: {batch[0].size()}')\n",
        "    print(f'Target vector size: {batch[1].size()}')\n",
        "    print(batch[0].dtype)\n",
        "    print(batch[1].dtype)\n",
        "    break\n",
        "\n",
        "print('\\nTest:')\n",
        "for batch in test_pad:\n",
        "    print(f'Text matrix size: {batch[0].size()}')\n",
        "    print(f'Target vector size: {batch[1].size()}')\n",
        "    print(batch[0].dtype)\n",
        "    print(batch[1].dtype)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9vk8rb45gBH",
        "outputId": "d6e4ee01-5dc6-43d9-f449-401cf295b931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "Text matrix size: torch.Size([128, 250])\n",
            "Target vector size: torch.Size([128, 1])\n",
            "torch.int64\n",
            "torch.int64\n",
            "\n",
            "Valid:\n",
            "Text matrix size: torch.Size([128, 134])\n",
            "Target vector size: torch.Size([128, 1])\n",
            "torch.int64\n",
            "torch.int64\n",
            "\n",
            "Test:\n",
            "Text matrix size: torch.Size([128, 381])\n",
            "Target vector size: torch.Size([128, 1])\n",
            "torch.int64\n",
            "torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfXDW4X3YQle"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcllDPmyYO8s"
      },
      "outputs": [],
      "source": [
        "class RNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
        "        #self.rnn = torch.nn.RNN(embedding_dim,\n",
        "        #                        hidden_dim,\n",
        "        #                        nonlinearity='relu')\n",
        "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
        "                                 hidden_dim, batch_first=True)\n",
        "\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, text):\n",
        "        # text dim: [batch size, sentence length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded dim: [batch size, sentence length, embedding dim]\n",
        "        output, (hidden, cell) = self.rnn(embedded)\n",
        "        # output dim: [batch size, sentence length, hidden dim]\n",
        "        # hidden dim: [1, batch size, hidden dim]\n",
        "        hidden.squeeze_(0)\n",
        "        # hidden dim: [batch size, hidden dim]\n",
        "        output = self.fc(hidden)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HS3SJRHYYTtj"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "model = RNN(input_dim=len(train_vocab),\n",
        "            embedding_dim=EMBEDDING_DIM,\n",
        "            hidden_dim=HIDDEN_DIM,\n",
        "            output_dim=NUM_CLASSES # could use 1 for binary classification\n",
        ")\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmYovvXSYWk0"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0S6fIMBUYVrs"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        correct_pred, num_examples = 0, 0\n",
        "\n",
        "        for i, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "            features = features.to(device)\n",
        "            targets = targets.float().to(device).squeeze_(1)\n",
        "\n",
        "            logits = model(features)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSDea42mYZpv",
        "outputId": "911ddb61-7e58-457f-9203-e82d939dc856"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/015 | Batch 000/265 | Loss: 0.6925\n",
            "Epoch: 001/015 | Batch 050/265 | Loss: 0.6926\n",
            "Epoch: 001/015 | Batch 100/265 | Loss: 0.6927\n",
            "Epoch: 001/015 | Batch 150/265 | Loss: 0.6917\n",
            "Epoch: 001/015 | Batch 200/265 | Loss: 0.6910\n",
            "Epoch: 001/015 | Batch 250/265 | Loss: 0.6985\n",
            "training accuracy: 50.58%\n",
            "valid accuracy: 49.40%\n",
            "Time elapsed: 1.32 min\n",
            "Epoch: 002/015 | Batch 000/265 | Loss: 0.6926\n",
            "Epoch: 002/015 | Batch 050/265 | Loss: 0.6926\n",
            "Epoch: 002/015 | Batch 100/265 | Loss: 0.6951\n",
            "Epoch: 002/015 | Batch 150/265 | Loss: 0.6643\n",
            "Epoch: 002/015 | Batch 200/265 | Loss: 0.6591\n",
            "Epoch: 002/015 | Batch 250/265 | Loss: 0.6579\n",
            "training accuracy: 70.03%\n",
            "valid accuracy: 66.23%\n",
            "Time elapsed: 2.63 min\n",
            "Epoch: 003/015 | Batch 000/265 | Loss: 0.5975\n",
            "Epoch: 003/015 | Batch 050/265 | Loss: 0.6257\n",
            "Epoch: 003/015 | Batch 100/265 | Loss: 0.4978\n",
            "Epoch: 003/015 | Batch 150/265 | Loss: 0.3462\n",
            "Epoch: 003/015 | Batch 200/265 | Loss: 0.4037\n",
            "Epoch: 003/015 | Batch 250/265 | Loss: 0.3248\n",
            "training accuracy: 90.10%\n",
            "valid accuracy: 86.83%\n",
            "Time elapsed: 3.98 min\n",
            "Epoch: 004/015 | Batch 000/265 | Loss: 0.2833\n",
            "Epoch: 004/015 | Batch 050/265 | Loss: 0.2802\n",
            "Epoch: 004/015 | Batch 100/265 | Loss: 0.1968\n",
            "Epoch: 004/015 | Batch 150/265 | Loss: 0.2285\n",
            "Epoch: 004/015 | Batch 200/265 | Loss: 0.3239\n",
            "Epoch: 004/015 | Batch 250/265 | Loss: 0.1636\n",
            "training accuracy: 93.50%\n",
            "valid accuracy: 87.67%\n",
            "Time elapsed: 5.39 min\n",
            "Epoch: 005/015 | Batch 000/265 | Loss: 0.1992\n",
            "Epoch: 005/015 | Batch 050/265 | Loss: 0.1260\n",
            "Epoch: 005/015 | Batch 100/265 | Loss: 0.1432\n",
            "Epoch: 005/015 | Batch 150/265 | Loss: 0.1014\n",
            "Epoch: 005/015 | Batch 200/265 | Loss: 0.1773\n",
            "Epoch: 005/015 | Batch 250/265 | Loss: 0.1428\n",
            "training accuracy: 96.94%\n",
            "valid accuracy: 88.40%\n",
            "Time elapsed: 6.71 min\n",
            "Epoch: 006/015 | Batch 000/265 | Loss: 0.0777\n",
            "Epoch: 006/015 | Batch 050/265 | Loss: 0.0870\n",
            "Epoch: 006/015 | Batch 100/265 | Loss: 0.1994\n",
            "Epoch: 006/015 | Batch 150/265 | Loss: 0.1823\n",
            "Epoch: 006/015 | Batch 200/265 | Loss: 0.1345\n",
            "Epoch: 006/015 | Batch 250/265 | Loss: 0.0784\n",
            "training accuracy: 98.01%\n",
            "valid accuracy: 88.28%\n",
            "Time elapsed: 8.03 min\n",
            "Epoch: 007/015 | Batch 000/265 | Loss: 0.0432\n",
            "Epoch: 007/015 | Batch 050/265 | Loss: 0.0670\n",
            "Epoch: 007/015 | Batch 100/265 | Loss: 0.0538\n",
            "Epoch: 007/015 | Batch 150/265 | Loss: 0.0658\n",
            "Epoch: 007/015 | Batch 200/265 | Loss: 0.0662\n",
            "Epoch: 007/015 | Batch 250/265 | Loss: 0.0331\n",
            "training accuracy: 98.84%\n",
            "valid accuracy: 88.60%\n",
            "Time elapsed: 9.34 min\n",
            "Epoch: 008/015 | Batch 000/265 | Loss: 0.0400\n",
            "Epoch: 008/015 | Batch 050/265 | Loss: 0.0262\n",
            "Epoch: 008/015 | Batch 100/265 | Loss: 0.0521\n",
            "Epoch: 008/015 | Batch 150/265 | Loss: 0.0470\n",
            "Epoch: 008/015 | Batch 200/265 | Loss: 0.0795\n",
            "Epoch: 008/015 | Batch 250/265 | Loss: 0.0148\n",
            "training accuracy: 99.09%\n",
            "valid accuracy: 88.33%\n",
            "Time elapsed: 10.68 min\n",
            "Epoch: 009/015 | Batch 000/265 | Loss: 0.0163\n",
            "Epoch: 009/015 | Batch 050/265 | Loss: 0.1151\n",
            "Epoch: 009/015 | Batch 100/265 | Loss: 0.0061\n",
            "Epoch: 009/015 | Batch 150/265 | Loss: 0.0349\n",
            "Epoch: 009/015 | Batch 200/265 | Loss: 0.0520\n",
            "Epoch: 009/015 | Batch 250/265 | Loss: 0.0647\n",
            "training accuracy: 99.29%\n",
            "valid accuracy: 88.73%\n",
            "Time elapsed: 12.00 min\n",
            "Epoch: 010/015 | Batch 000/265 | Loss: 0.0250\n",
            "Epoch: 010/015 | Batch 050/265 | Loss: 0.0528\n",
            "Epoch: 010/015 | Batch 100/265 | Loss: 0.0164\n",
            "Epoch: 010/015 | Batch 150/265 | Loss: 0.0110\n",
            "Epoch: 010/015 | Batch 200/265 | Loss: 0.0248\n",
            "Epoch: 010/015 | Batch 250/265 | Loss: 0.0676\n",
            "training accuracy: 99.11%\n",
            "valid accuracy: 88.37%\n",
            "Time elapsed: 13.33 min\n",
            "Epoch: 011/015 | Batch 000/265 | Loss: 0.0446\n",
            "Epoch: 011/015 | Batch 050/265 | Loss: 0.0127\n",
            "Epoch: 011/015 | Batch 100/265 | Loss: 0.0210\n",
            "Epoch: 011/015 | Batch 150/265 | Loss: 0.0317\n",
            "Epoch: 011/015 | Batch 200/265 | Loss: 0.0228\n",
            "Epoch: 011/015 | Batch 250/265 | Loss: 0.0125\n",
            "training accuracy: 99.05%\n",
            "valid accuracy: 87.85%\n",
            "Time elapsed: 14.65 min\n",
            "Epoch: 012/015 | Batch 000/265 | Loss: 0.0322\n",
            "Epoch: 012/015 | Batch 050/265 | Loss: 0.0181\n",
            "Epoch: 012/015 | Batch 100/265 | Loss: 0.0124\n",
            "Epoch: 012/015 | Batch 150/265 | Loss: 0.0095\n",
            "Epoch: 012/015 | Batch 200/265 | Loss: 0.0977\n",
            "Epoch: 012/015 | Batch 250/265 | Loss: 0.0064\n",
            "training accuracy: 99.53%\n",
            "valid accuracy: 87.93%\n",
            "Time elapsed: 15.98 min\n",
            "Epoch: 013/015 | Batch 000/265 | Loss: 0.0100\n",
            "Epoch: 013/015 | Batch 050/265 | Loss: 0.0206\n",
            "Epoch: 013/015 | Batch 100/265 | Loss: 0.0363\n",
            "Epoch: 013/015 | Batch 150/265 | Loss: 0.0068\n",
            "Epoch: 013/015 | Batch 200/265 | Loss: 0.0152\n",
            "Epoch: 013/015 | Batch 250/265 | Loss: 0.0085\n",
            "training accuracy: 99.51%\n",
            "valid accuracy: 88.48%\n",
            "Time elapsed: 17.30 min\n",
            "Epoch: 014/015 | Batch 000/265 | Loss: 0.0295\n",
            "Epoch: 014/015 | Batch 050/265 | Loss: 0.0621\n",
            "Epoch: 014/015 | Batch 100/265 | Loss: 0.0260\n",
            "Epoch: 014/015 | Batch 150/265 | Loss: 0.0255\n",
            "Epoch: 014/015 | Batch 200/265 | Loss: 0.0904\n",
            "Epoch: 014/015 | Batch 250/265 | Loss: 0.0679\n",
            "training accuracy: 99.56%\n",
            "valid accuracy: 87.73%\n",
            "Time elapsed: 18.62 min\n",
            "Epoch: 015/015 | Batch 000/265 | Loss: 0.0843\n",
            "Epoch: 015/015 | Batch 050/265 | Loss: 0.0198\n",
            "Epoch: 015/015 | Batch 100/265 | Loss: 0.0252\n",
            "Epoch: 015/015 | Batch 150/265 | Loss: 0.0130\n",
            "Epoch: 015/015 | Batch 200/265 | Loss: 0.0363\n",
            "Epoch: 015/015 | Batch 250/265 | Loss: 0.0048\n",
            "training accuracy: 99.65%\n",
            "valid accuracy: 88.28%\n",
            "Time elapsed: 19.95 min\n",
            "Total Training Time: 19.95 min\n",
            "Test accuracy: 88.90%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    for batch_idx, batch_data in enumerate(train_pad):\n",
        "\n",
        "        text = batch_data[0].to(DEVICE)\n",
        "        labels = batch_data[1].to(DEVICE).squeeze_(1)\n",
        "\n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits = model(text)\n",
        "        # import pdb; pdb.set_trace()\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "\n",
        "        ### LOGGING\n",
        "        if not batch_idx % 50:\n",
        "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
        "                   f'Batch {batch_idx:03d}/{34000//BATCH_SIZE :03d} | '\n",
        "                   f'Loss: {loss:.4f}')\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        print(f'training accuracy: '\n",
        "              f'{compute_accuracy(model, train_pad, DEVICE):.2f}%'\n",
        "              f'\\nvalid accuracy: '\n",
        "              f'{compute_accuracy(model, valid_pad, DEVICE):.2f}%')\n",
        "\n",
        "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
        "\n",
        "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
        "print(f'Test accuracy: {compute_accuracy(model, test_pad, DEVICE):.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apQ2dPgXYcJl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "217c0ed1-c006-4e2e-c2f4-62f3ac123379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability positive:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8687519431114197"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "def predict_sentiment(model, sentence):\n",
        "\n",
        "    model.eval()\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    indexed = [train_vocab.get_stoi()[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = torch.nn.functional.softmax(model(tensor), dim=1)\n",
        "    return prediction[0][0].item()\n",
        "\n",
        "print('Probability positive:')\n",
        "predict_sentiment(model, \"This is such an awesome movie, I really love it!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXaqqfheYfIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9943e489-1db3-4d3c-bcaf-6f45edf468fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability negative:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6380993723869324"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "print('Probability negative:')\n",
        "1-predict_sentiment(model, \"I really hate this movie. It is really bad and sucks!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdQK3oc3YhQy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}