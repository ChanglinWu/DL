{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChanglinWu/DL/blob/main/IRIS_Classification_MLP3_98_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple PyTorch MLP Iris Flower Classification\n",
        "\n",
        "This example shows how to implement a 3-layer Multi-Layer Perceptron (MLP) model (ask as feedforward neural network) for Iris flower classification using the well-known Iris dataset.\n",
        "\n",
        "The Iris dataset is a classic dataset that is commonly used to demonstrate supervised learning techniques in machine learning and deep learning. It was introduced by statistician Ronald Fisher in his 1936 paper \"The Use of Multiple Measurements in Taxonomic Problems\".\n",
        "\n",
        "<img src='https://www.ee.cityu.edu.hk/~lmpo/ee5438/images/iris_mlp_classifier.png'>\n",
        "\n",
        "The dataset contains 150 samples of iris flowers from three different species - Iris setosa, Iris versicolor and Iris virginica. Each sample contains the following four features:\n",
        "\n",
        "- Sepal length in cm\n",
        "- Sepal width in cm\n",
        "- Petal length in cm\n",
        "- Petal width in cm\n",
        "\n",
        "The dataset contains 50 samples from each of the three iris species. One flower species is linearly separable from the other two, but the other two species are not linearly separable from each other.\n",
        "\n",
        "References:\n",
        "\n",
        "- [Mastering Pandas DataFrames for Machine Learning](https://pub.aimind.so/mastering-pandas-dataframes-for-machine-learning-490896e73a3a)\n"
      ],
      "metadata": {
        "id": "IOFsWiHMtUsb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6s0DklYBrLcZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df = pd.read_csv(\"https://www.ee.cityu.edu.hk/~lmpo/ee5438/data/iris.csv\", na_values=[\"NA\", \"?\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the IRIS dataset from a CSV file into a Pandas dataframe. We will use these four numeric values as features for IRIS specie classificaiton."
      ],
      "metadata": {
        "id": "To8kisFRuKIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BTiXmcl6uBUB",
        "outputId": "f7e7a139-0322-43ab-d5a5-8abf2eb27e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
              "0      1            5.1           3.5            1.4           0.2   \n",
              "1      2            4.9           3.0            1.4           0.2   \n",
              "2      3            4.7           3.2            1.3           0.2   \n",
              "3      4            4.6           3.1            1.5           0.2   \n",
              "4      5            5.0           3.6            1.4           0.2   \n",
              "..   ...            ...           ...            ...           ...   \n",
              "145  146            6.7           3.0            5.2           2.3   \n",
              "146  147            6.3           2.5            5.0           1.9   \n",
              "147  148            6.5           3.0            5.2           2.0   \n",
              "148  149            6.2           3.4            5.4           2.3   \n",
              "149  150            5.9           3.0            5.1           1.8   \n",
              "\n",
              "            Species  \n",
              "0       Iris-setosa  \n",
              "1       Iris-setosa  \n",
              "2       Iris-setosa  \n",
              "3       Iris-setosa  \n",
              "4       Iris-setosa  \n",
              "..              ...  \n",
              "145  Iris-virginica  \n",
              "146  Iris-virginica  \n",
              "147  Iris-virginica  \n",
              "148  Iris-virginica  \n",
              "149  Iris-virginica  \n",
              "\n",
              "[150 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7afd11dd-f40e-473f-9dfc-b0beef61bf14\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>146</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>147</td>\n",
              "      <td>6.3</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.9</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>148</td>\n",
              "      <td>6.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>149</td>\n",
              "      <td>6.2</td>\n",
              "      <td>3.4</td>\n",
              "      <td>5.4</td>\n",
              "      <td>2.3</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>150</td>\n",
              "      <td>5.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.1</td>\n",
              "      <td>1.8</td>\n",
              "      <td>Iris-virginica</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7afd11dd-f40e-473f-9dfc-b0beef61bf14')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7afd11dd-f40e-473f-9dfc-b0beef61bf14 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7afd11dd-f40e-473f-9dfc-b0beef61bf14');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f1e981ce-65b2-4c86-9e0d-f96179146cc3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f1e981ce-65b2-4c86-9e0d-f96179146cc3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f1e981ce-65b2-4c86-9e0d-f96179146cc3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We convert the Pandas dataframe into NumPy arrays, then into PyTorch tensors. We use all four features as input features to classify the species."
      ],
      "metadata": {
        "id": "iWq9kN4Muvjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LabelEncoder() from scikit-learn is used to encode categorical values to numeric labels.\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "x = df[[\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]].values\n",
        "y = le.fit_transform(df[\"Species\"])\n",
        "species = le.classes_\n",
        "\n",
        "x = torch.tensor(x, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "eBmyKRImslP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are designing a feedforward neural network, also called a multilayer perceptron (MLP), that can automatically detect the number of input features and create the input layer accordingly.\n",
        "\n",
        "In this example, there are 4 input features (Sepal length, Sepal width,\n",
        "Petal length, and Petal width) based on the Iris dataset. These 4 input features connect to a hidden layer with 25 neurons. This hidden layer then connects to another hidden layer with 15 neurons. The Relu activation functions are used for the two hidden layers.\n",
        "\n",
        "The output layer should have a number of neurons matching the number of classes, which is 3 for the Iris dataset. The Softmax function is used for the output layer. CrossEntropyLoss is used as the loss function.\n",
        "\n",
        "Softmax is commonly used in classification problems because it converts the raw outputs into normalized probability scores for each class. This allows us to interpret the predictions as confidence levels and pick the class with the highest probability.\n"
      ],
      "metadata": {
        "id": "kT4EQ8q0vHet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "    nn.Linear(x.shape[1], 25),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(25, 15),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(15, len(species)),\n",
        "    nn.Softmax(dim=1),\n",
        ")"
      ],
      "metadata": {
        "id": "yXzBDp1_spqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compile the model using the AOT (ahead-of-time) compilation feature in the eager mode backend. AOT compilation allows you to optimize and prepare the model for execution ahead of time, which can improve inference speed.\n",
        "\n",
        "We use Cross Entropy Loss function, which is common for multi-class classificaiton tasks.\n",
        "\n",
        "To train the model, we utilize the Stochastic Gradient Descent (SGD) optimizer with a learning rate of 0.01. SGD is a basic optimization algorithm for neural network training. The learning rate determines the step size taken during optimization, and in this case, 0.01 is a reasonable starting value. However, you can experiment with different optimizers like Adam and adjust the learning rate within the range of 0 to 1 to find the optimal performance. Setting the learning rate correctly is important, as too high or too low values can negatively impact the training process."
      ],
      "metadata": {
        "id": "K4nmNWihqr9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch 2.0 Model Compile\n",
        "# Enables ahead-of-time (AOT) compilation using the eager mode backend.\n",
        "model = torch.compile(model,backend=\"aot_eager\")\n",
        "\n",
        "cross_entropy_loss = nn.CrossEntropyLoss()  # cross entropy loss\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)  # SGD optimizer\n",
        "\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # Adam optimizer"
      ],
      "metadata": {
        "id": "zr-nr36asroh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We call the train() function to tell PyTorch we are now training the model. Later, we call the eval() function to tell PyTorch we are now evaluating the model."
      ],
      "metadata": {
        "id": "D02CSx_MyRjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(2000):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(x)\n",
        "    # CrossEntropyLoss combines nn.Softmax() and nn.NLLLoss()\n",
        "    loss = cross_entropy_loss(out, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, loss: {loss.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2yJw355suFY",
        "outputId": "05fa797d-533e-431b-c6ce-9b49763055e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, loss: 1.1241774559020996\n",
            "Epoch 100, loss: 1.0835837125778198\n",
            "Epoch 200, loss: 1.0565294027328491\n",
            "Epoch 300, loss: 1.0182915925979614\n",
            "Epoch 400, loss: 0.9746531248092651\n",
            "Epoch 500, loss: 0.9259414672851562\n",
            "Epoch 600, loss: 0.878994882106781\n",
            "Epoch 700, loss: 0.8453763723373413\n",
            "Epoch 800, loss: 0.8200873732566833\n",
            "Epoch 900, loss: 0.7983616590499878\n",
            "Epoch 1000, loss: 0.7777446508407593\n",
            "Epoch 1100, loss: 0.7570653557777405\n",
            "Epoch 1200, loss: 0.7361510396003723\n",
            "Epoch 1300, loss: 0.7156763076782227\n",
            "Epoch 1400, loss: 0.696642279624939\n",
            "Epoch 1500, loss: 0.6797868609428406\n",
            "Epoch 1600, loss: 0.6654560565948486\n",
            "Epoch 1700, loss: 0.6535544395446777\n",
            "Epoch 1800, loss: 0.6437768340110779\n",
            "Epoch 1900, loss: 0.6357559561729431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have finished training the neural network model, we want to use it to make predictions.\n",
        "\n",
        "The code below uses the trained model to generate predictions. Just like before, it will return 3 prediction values for each of the 150 iris flower samples. This is because there were 3 types of iris flowers (Iris-setosa, Iris-versicolor, and Iris-virginica)."
      ],
      "metadata": {
        "id": "njNcpWWhryw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out number of species found:\n",
        "\n",
        "print(species)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwEYNjIDrn91",
        "outputId": "d6467470-d246-4342-e3b2-dcb7eaab5444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We call the eval() function to tell PyTorch that we are no longer training the model. Instead, we want to evaluate the trained model and generate predictions.\n",
        "\n",
        "By putting the model in evaluation mode, PyTorch will turn off things like dropout layers and batch normalization layers. This allows us to get predictions that are optimized for inference rather than training."
      ],
      "metadata": {
        "id": "iUtSXSJbrEPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "pred = model(x)\n",
        "print(f\"Shape: {pred.shape}\")\n",
        "print(pred[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dOChbQbru_w",
        "outputId": "fdf3eda9-0505-4883-8794-b68fdff7292b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([150, 3])\n",
            "tensor([[9.8849e-01, 1.1509e-02, 6.3188e-09],\n",
            "        [9.8342e-01, 1.6579e-02, 3.2629e-08],\n",
            "        [9.8402e-01, 1.5984e-02, 2.7161e-08],\n",
            "        [9.8047e-01, 1.9531e-02, 6.7597e-08],\n",
            "        [9.8843e-01, 1.1569e-02, 6.4286e-09],\n",
            "        [9.9043e-01, 9.5744e-03, 2.8586e-09],\n",
            "        [9.8363e-01, 1.6373e-02, 3.0364e-08],\n",
            "        [9.8658e-01, 1.3415e-02, 1.2649e-08],\n",
            "        [9.7696e-01, 2.3037e-02, 1.4081e-07],\n",
            "        [9.8386e-01, 1.6138e-02, 2.8983e-08]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scientific notation is a way to write very large or very small numbers compactly in the form of a number multiplied by a power of 10. If you would like to turn of scientific notation, the following line can be used:"
      ],
      "metadata": {
        "id": "xNQ63VgRr33M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)"
      ],
      "metadata": {
        "id": "VBjni6vVr00f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we see these values rounded up."
      ],
      "metadata": {
        "id": "6qZ03Uhyr68q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred[0:10].detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLu3m3Ebr6WI",
        "outputId": "be871c90-7174-4028-97ce-f58904afb884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.9884913  0.01150869 0.00000001]\n",
            " [0.98342127 0.01657872 0.00000003]\n",
            " [0.9840164  0.0159836  0.00000003]\n",
            " [0.9804685  0.01953143 0.00000007]\n",
            " [0.98843074 0.0115693  0.00000001]\n",
            " [0.99042565 0.00957435 0.        ]\n",
            " [0.98362696 0.01637298 0.00000003]\n",
            " [0.9865849  0.01341505 0.00000001]\n",
            " [0.97696334 0.02303652 0.00000014]\n",
            " [0.98386186 0.01613817 0.00000003]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typically, the model predicts the class with the highest prediction score.\n",
        "\n",
        "The argmax function finds the index of the maximum prediction for each sample.\n",
        "\n",
        "We can use argmax to get the highest prediction column.\n",
        "\n",
        "Then we lookup the actual class name using that column index.\n",
        "\n",
        "This automatically converts the predictions to class names."
      ],
      "metadata": {
        "id": "LAvwhyMXsArh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, predict_classes = torch.max(pred, 1)\n",
        "print(f\"Predictions: {predict_classes}\")\n",
        "print(f\"Expected: {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-pyCkgJr-Kc",
        "outputId": "e4e53285-52f4-4828-a824-18050478b7c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
            "        2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2])\n",
            "Expected: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is easy to turn the index numbers back into the names of the iris species. We can use the list of species names that we created before."
      ],
      "metadata": {
        "id": "JBTkDw0SsFDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(species[predict_classes[1:10]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62opKpT7sCoB",
        "outputId": "0194bf0a-9b09-4079-cd51-50fe31fe3bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy is an error measurement that is easy to understand. It is like a test score. For all the iris flower predictions the neural network made, what percent were right? The problem with only using accuracy is that it does not think about how sure the neural network was for each prediction."
      ],
      "metadata": {
        "id": "Hgk0LiC_sJiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = accuracy_score(y, predict_classes)\n",
        "print(f\"Accuracy: {correct}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZIOjsLCsHFZ",
        "outputId": "59639817-346f-4177-e9b6-0f518f9d9a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf_mat = confusion_matrix(predict_classes, y)\n",
        "print(f\"Confusion Matrix \\n {conf_mat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA-3ei3bhEVO",
        "outputId": "6bd60412-0163-4f0d-b324-828a39eee9cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix \n",
            " [[50  0  0]\n",
            " [ 0 47  0]\n",
            " [ 0  3 50]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code makes two predictions. The first prediction is for one iris flower. The second prediction is for two iris flowers. For the second prediction, we use \"argmax\" and say axis=1. This is because now we have a 2D array instead of 1D array. By saying axis=1, we tell it to find the maximum column index for each row. This lets us get the predicted class for each of the two flowers"
      ],
      "metadata": {
        "id": "sVBCKt_d0H8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_flower = torch.tensor([[6.7, 4.5, 5.0, 2.4]])\n",
        "pred = model(sample_flower)\n",
        "print(pred)\n",
        "_, predict_classes = torch.max(pred, 1)\n",
        "print(f\"Predict that {sample_flower} is: {species[predict_classes]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tabj1JIcsLRu",
        "outputId": "1433f120-1959-4870-9a5d-023d92f858e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0012, 0.9282, 0.0706]], grad_fn=<CompiledFunctionBackward>)\n",
            "Predict that tensor([[6.7000, 4.5000, 5.0000, 2.4000]]) is: Iris-versicolor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also make predictions for two sample flowers at the same time:"
      ],
      "metadata": {
        "id": "GW_BEYi_sSXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_flower = torch.tensor(\n",
        "    [[6.7, 4.5, 5.0, 2.4], [5.2, 3.5, 1.5, 0.8], [5.8, 3.1, 5.2, 1.9]])\n",
        "pred = model(sample_flower)\n",
        "print(pred)\n",
        "_, predict_classes = torch.max(pred, 1)\n",
        "print(f\"Predict that these two flowers {sample_flower} \")\n",
        "print(f\"are: {species[predict_classes.cpu().detach()]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKxOpDQ9sPjJ",
        "outputId": "3393efaf-3901-4d78-ccd7-6fa897fc0f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.2075e-03, 9.2822e-01, 7.0572e-02],\n",
            "        [9.8302e-01, 1.6981e-02, 1.8414e-08],\n",
            "        [1.6020e-05, 9.3275e-02, 9.0671e-01]],\n",
            "       grad_fn=<CompiledFunctionBackward>)\n",
            "Predict that these two flowers tensor([[6.7000, 4.5000, 5.0000, 2.4000],\n",
            "        [5.2000, 3.5000, 1.5000, 0.8000],\n",
            "        [5.8000, 3.1000, 5.2000, 1.9000]]) \n",
            "are: ['Iris-versicolor' 'Iris-setosa' 'Iris-virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "spoKpaMZsbeO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}